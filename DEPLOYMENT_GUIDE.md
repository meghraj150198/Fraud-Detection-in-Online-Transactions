# Fraud Detection Model - Deployment Guide

## ðŸš€ Production Deployment

### Overview
The fraud detection system is production-ready with:
- **92.85% accuracy** on test data
- **87.71% fraud detection rate** (recall)
- **3.01% false alarm rate**
- Real-time scoring capability
- Batch processing support
- REST API ready

---

## Quick Start

### 1. Initialize Scoring Service

```python
from fraud_scoring_service import FraudScoringService

# Initialize service
service = FraudScoringService(
    model_artifacts_path='ml_model_artifacts.pkl',
    feature_data_path='sales_with_fraud_indicators.csv'
)
```

### 2. Score Single Transaction

```python
transaction = {
    'selling_price': 450.00,
    'quantity_ordered': 2,
    'velocity_spike': 0,
    # ... all 49 required features
}

response = service.score_single_transaction(transaction)
print(response['prediction']['risk_level'])  # Output: 'Low', 'Medium', or 'High'
```

### 3. Batch Score Transactions

```python
import pandas as pd

# Load transaction batch
transactions_df = pd.read_csv('new_transactions.csv')

# Score all
results = service.score_transactions(transactions_df)

# Get fraud flagged ones
fraud_transactions = results[results['is_fraud_flagged'] == 1]
```

---

## API Response Format

### Single Transaction Response

```json
{
  "status": "success",
  "timestamp": "2026-02-09T04:15:29.217",
  "prediction": {
    "risk_level": "Low",
    "risk_score": 99.71,
    "confidence": 99.71,
    "is_flagged": false,
    "class_probabilities": {
      "low": 99.71,
      "medium": 0.29,
      "high": 0.00
    }
  }
}
```

### Batch Results DataFrame

| Column | Description |
|--------|-------------|
| `transaction_id` | Unique transaction identifier |
| `predicted_risk_level` | Low, Medium, or High |
| `risk_score` | 0-100 risk score |
| `confidence` | Model confidence in prediction |
| `prob_low` | Low risk probability % |
| `prob_medium` | Medium risk probability % |
| `prob_high` | High risk probability % |
| `is_fraud_flagged` | 1 if Medium/High, 0 if Low |

---

## Model Performance

### Classification Metrics

| Metric | Value |
|--------|-------|
| Accuracy | 92.85% |
| Precision (weighted) | 92.79% |
| Recall (weighted) | 92.85% |
| Recall (macro) | 72.06% |
| F1-Score | 92.63% |

### Per-Class Performance

| Risk Level | Precision | Recall | F1-Score | Support |
|-----------|-----------|--------|----------|---------|
| High | 88.89% | 32.00% | 47.06% | 50 |
| Low | 93.41% | 96.99% | 95.17% | 2,821 |
| Medium | 91.76% | 87.18% | 89.41% | 1,521 |

### Detection Effectiveness

- **Fraud Caught**: 87.71% (1,378 of 1,571 fraud cases)
- **False Alarms**: 3.01% (85 legitimate flagged as fraud)
- **Correct Clearances**: 96.99% (2,736 legitimate correctly approved)

---

## Feature Groups & Importance

### Top Signals by Group

| Signal Group | Top Feature | Importance |
|-------------|-----------|-----------|
| **Behavioral Meta** | combined_risk_index | 50.66% |
| **Amount** | price_deviation_from_sku_avg | 27.31% |
| **IP/Historical** | account_compromise_risk | 50.07% |
| **Device/Location** | location_deviation_from_baseline | 79.08% |
| **Merchant** | merchant_risk_score | 50.20% |
| **Velocity** | units_zscore_7d | 53.27% |
| **Temporal** | transaction_hour | 42.33% |
| **Payment** | is_low_amount | 40.10% |

---

## Deployment Options

### Option 1: Python Library (Recommended for Python apps)

```python
from fraud_scoring_service import FraudScoringService

service = FraudScoringService()
results = service.score_transactions(df)
```

### Option 2: REST API (Recommended for web services)

```bash
pip install flask
python fraud_scoring_service_api.py
```

**Endpoints:**
- `GET /health` - Health check
- `POST /score` - Score single transaction
- `POST /score-batch` - Score multiple transactions
- `GET /stats` - Get model statistics

### Option 3: Docker Container (Recommended for deployment)

```bash
docker build -t fraud-detector:v1.0 .
docker run -p 5000:5000 fraud-detector:v1.0
```

---

## Monitoring & Logging

### Available Logs

The service logs to both file and console:
- **File**: `fraud_scoring.log`
- **Console**: Real-time output

### Log Entries

```
[2026-02-09 04:15:27,413] INFO: Initializing Fraud Scoring Service...
[2026-02-09 04:15:28,587] INFO: âœ“ Model loaded with 49 features
[2026-02-09 04:15:28,780] INFO: Scoring 100 transactions...
[2026-02-09 04:15:29,171] INFO: âœ“ Scored 100 transactions
[2026-02-09 04:15:29,171] INFO:   â€¢ Fraud Flagged: 24 (24.00%)
[2026-02-09 04:15:29,171] INFO:   â€¢ Average Risk Score: 98.77/100
```

### Service Statistics

```
Total Transactions Scored: 101
Total Fraud Flagged: 24
Fraud Flag Rate: 23.76%
```

---

## Decision Thresholds

### Default Risk Classifications

| Risk Level | Score Range | Action |
|-----------|------------|--------|
| **Low** | < 50 | Auto-approve |
| **Medium** | 50-75 | Manual review required |
| **High** | > 75 | Block/Investigate |

### Customization

```python
# Adjust risk thresholds for business needs
if risk_score < 30:
    action = 'auto_approve'
elif risk_score < 60:
    action = 'send_otp'
elif risk_score < 80:
    action = 'manual_review'
else:
    action = 'block'
```

---

## Model Maintenance

### Retraining Schedule

- **Quarterly**: Complete retraining with new data
- **Monthly**: Evaluate model drift
- **Weekly**: Monitor fraud detection rates

### Performance Monitoring

```python
# Check model stats
stats = service.get_model_stats()
print(stats['training_metrics'])
```

### Update Procedure

1. Collect new labeled data (minimum 3 months)
2. Retrain: `python ml_models.py`
3. Validate performance on holdout set
4. Update artifacts: `cp ml_model_artifacts.pkl ml_model_artifacts.backup.pkl`
5. Deploy new model

---

## Error Handling

### Graceful Degradation

```python
try:
    response = service.score_single_transaction(tx_data)
except Exception as e:
    logger.error(f"Scoring error: {e}")
    # Default to manual review for safety
    response = {'risk_level': 'Medium', 'reason': 'Scoring unavailable'}
```

### Common Issues

| Issue | Solution |
|-------|----------|
| Missing features | Filled from training data mean |
| NaN values | Imputed automatically |
| Model not loaded | Check model_artifacts.pkl path |
| Low confidence | Review and adjust thresholds |

---

## Performance Optimization

### Batch Processing (Recommended)

```python
# Efficient for high volume
results = service.score_transactions(df)  # 10,000+ transactions
```

### Real-time Scoring

```python
# Fast response for individual transactions
response = service.score_single_transaction(tx_dict)
```

### Throughput

- **Single transaction**: ~500ms per transaction
- **Batch (1000 tx)**: ~3-5 seconds
- **Throughput**: ~200-300 transactions/second

---

## Files Generated by Deployment

| File | Description |
|------|-------------|
| `ml_model_artifacts.pkl` | Serialized model & scalers |
| `fraud_scoring.log` | Scoring service logs |
| `fraud_scores_batch_sample.csv` | Sample scored transactions |
| `model_stats.json` | Model performance metrics |

---

## Next Steps

1. âœ… **Testing**: Run `fraud_scoring_service.py` to validate
2. âœ… **Integration**: Connect to transaction processing system
3. â³ **Monitoring**: Set up alerts for high fraud rates
4. â³ **Optimization**: Calibrate thresholds per business rules
5. â³ **Scaling**: Deploy to production infrastructure

---

## Support & Questions

For issues or questions:
1. Check `fraud_scoring.log` for error details
2. Review model performance: `model_stats.json`
3. Validate feature engineering: `sales_with_fraud_indicators.csv`
4. Retrain if performance degrades significantly

---

**Version**: 1.0  
**Last Updated**: 2026-02-09  
**Status**: Production Ready âœ…
